---
title: "Cleaning and LDA"
author: "Joaquin Dominguez"
date: "4/2/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r Cleaning}
library(tidyverse)

clean <-  df
```


```{r Age}
##examining numeric variables
##age
hist(clean$age)
head(clean)
clean %>% ggplot(aes(y = y, x = factor(age), fill = y)) + geom_bar(stat='identity')

## skewed right a little
```


```{r Balance}
##balance
hist(clean$balance)
hist(log(clean$balance))
summary(log(clean$balance))
clean %>% ggplot(aes(x = y, y = log(balance))) + geom_boxplot()
clean$balance <- log(clean$balance)

clean$balance[!is.infinite(rowSums(clean)),]
is.infinite(clean$balance)
clean <- clean %>% filter(!is.infinite(balance)) %>% filter(!is.na(balance))
clean %>% ggplot(aes(x = y, y = balance)) + geom_boxplot()
clean <- clean %>% filter(balance>=1)



## def log transform for balance

```


```{r day}
###day
### seems to be trending towards randomly distributed rather than normal, but it'll survive

hist(clean$day)
summary(clean$day)
```


```{r duration}
## duration
summary(clean$duration)
hist(log(clean$duration))

clean$duration <- log(clean$duration)
summary(clean$duration)
dim(clean)
clean <- clean %>% filter(!is.infinite(duration)) %>% filter(!is.na(duration))
hist(clean$duration)

clean %>% ggplot(aes(x = y, y = duration)) + geom_boxplot()
clean <- clean %>% filter(duration>=2)

###log transformed duration and removed outliers (under 2) to improve skewness
```


```{r campaign}
###campaign

summary(clean$campaign)
hist(1/(clean$campaign))

## Impossible to have normal distribution, considering nature of variable, might be worth removing
```


```{r pdays}
## pdays

hist(sqrt(clean$pdays))

clean %>% ggplot(aes(x=y, y = sqrt(pdays))) +geom_boxplot()

clean %>% mutate(pdays=sqrt(pdays)) %>% mutate(pdays=coalesce(pdays,0)) %>% count(pdays)


### sqrt is best transformation for pdays to approach normality, except it would 
###remove about 30,000 observations ince, you guessed it, the sqrt of 0 is 0. 
##Anyway, there are 30,000  observations with 0, so  highly unlikely this will be able
### tell us anything about 'y'
```


```{r previous}
hist(1/(clean$previous))

clean %>% ggplot(aes(x=y, y=previous)) + geom_boxplot()

##remove outlier
clean <- clean %>% filter(previous<100)

clean %>% mutate(previous=1/previous)

###reciprocal transformation makes the most sense for previous variable, but even then, it's not really  normally distributed
###might be worth removing,  especially, since the reason it makes the most sense is bc the 0 is removed,
## due to the majority of observations being 0, thus 1/0= undefined (or in this case, infinity). Traash.
```


```{r Mutate}

## make relevant transformations
clean <- clean %>% mutate(balance=log(balance)) %>% filter(balance>=1) %>% mutate(duration=log(duration)) %>% filter(duration>=2)
clean <- clean %>% filter(!is.infinite(balance)) %>% filter(!is.na(balance)) %>% filter(!is.infinite(duration)) %>% filter(!is.na(duration))


```


```{r train and test sets}

num_clean <- select_if(clean, is.numeric)
y_col<- clean$y


num_clean <- cbind(num_clean, y_col)
num_clean <- num_clean %>% mutate(y=y_col) %>% select(!y_col)

set.seed(1)
test_index <- sample(1:nrow(clean), size = 0.2*nrow(clean))
test <- clean[test_index,]
train<- clean[-test_index,]
dim(test)
dim(train)
head(train)
head(clean)

##set y as factor
train$y <- as.factor(train$y)
test$y <- as.factor(test$y)


```

```{r balance train set}
library(ROSE)
##under sampling
under_train <- ovun.sample(y~., data=train, method="under")
under_train <- under_train$data
table(under_train$y)
under_train$y <- as.factor(under_train$y)
head(under_train)

#over sampling
over_train <- ovun.sample(y~., data=train, method="over")
over_train <- over_train$data
table(over_train$y)

#both
both_train <- ovun.sample(y~., data=train, method="both")
both_train <- both_train$data
table(both_train$y)
head(under_train)
```


```{r LDA}
library(MASS)
library(caret)

#under sample
under_lda <- lda(y~age+balance+day+duration, data=under_train)
summary(under_lda)
pred <- predict(under_lda, newdata=test[,-8])$class

confusionMatrix(pred, test$y)

## Accuracy: 72.2%
## Sensitivity: 72%
## Specificity: 73.6%

#over sample
over_lda <- lda(y~age+balance+day+duration, data=over_train)
summary(over_lda)
pred_over <- predict(over_lda, newdata=test[,-8])$class

confusionMatrix(pred_over, test$y)


### Accuracy: 71.75%
### Sensitivity: 71.37%
### Specificity: 74.29%

# both sample
both_lda <- lda(y~age+balance+day+duration, data=both_train)
summary(both_lda)
pred_both <- predict(both_lda, newdata=test[,-8])$class

confusionMatrix(pred_both, test$y)

### Accuracy: 72.18%
### Sensitivity: 71.98%
### Specificity: 73.47%


### Under sample performed marginally better; however, given that only 4 numeric variables were used (only ones that met LDA assumptions), this method is not the best approach for this given dataset.
```


You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
