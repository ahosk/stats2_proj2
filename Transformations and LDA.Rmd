---
title: "Cleaning and LDA"
author: "Joaquin Dominguez"
date: "4/2/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r Cleaning}
library(tidyverse)

clean <-  df
```


```{r Age}
##examining numeric variables
##age
hist(clean$age)
head(clean)
clean %>% ggplot(aes(y = y, x = factor(age), fill = y)) + 
  geom_bar(stat='identity') + ggtitle("Distribution of Age") + 
  theme(axis.ticks.x=element_blank(), axis.text.x = element_blank(), axis.text.y = element_blank(), panel.background = element_blank()) + 
  labs(x = "Age", y = " ")

## skewed right a little
```


```{r Balance}
##balance
hist(clean$balance)
hist(log(clean$balance))
summary(log(clean$balance))
clean %>% ggplot(aes(x = y, y = log(balance))) + geom_boxplot()
clean$balance <- log(clean$balance)

clean$balance[!is.infinite(rowSums(clean)),]
is.infinite(clean$balance)
clean <- clean %>% filter(!is.infinite(balance)) %>% filter(!is.na(balance))
clean %>% ggplot(aes(x = y, y = balance)) + geom_boxplot() + theme_minimal() + labs(y = "balance") + ggtitle("Distribution of Balance")
clean <- clean %>% filter(balance>=1)




## def log transform for balance

```


```{r day}
###day
### seems to be trending towards randomly distributed rather than normal, but it'll survive

hist(clean$day)
summary(clean$day)

clean %>% ggplot(aes(x = day, fill = y)) + 
  geom_histogram() + ggtitle("Distribution of Day") + theme_minimal()


```


```{r duration}
## duration
summary(clean$duration)
hist(log(clean$duration))

clean$duration <- log(clean$duration)
summary(clean$duration)
dim(clean)
clean <- clean %>% filter(!is.infinite(duration)) %>% filter(!is.na(duration))
hist(clean$duration)

clean %>% ggplot(aes(x = y, y = duration)) + geom_boxplot()
clean %>% ggplot(aes(x = duration, fill = y)) + geom_histogram() + theme_minimal() + ggtitle("Distribution of Duration")

clean <- clean %>% filter(duration>=2)

###log transformed duration and removed outliers (under 2) to improve skewness
```


```{r campaign}
###campaign

clean %>% ggplot(aes(x = campaign, fill = y)) + geom_histogram() + theme_minimal() + ggtitle("Distribution of Campaign")

summary(clean$campaign)
hist(1/(clean$campaign))

## Impossible to have normal distribution, considering nature of variable, might be worth removing
```


```{r pdays}
## pdays

hist(sqrt(clean$pdays))

clean %>% ggplot(aes(x=y, y = sqrt(pdays))) +geom_boxplot()

clean %>% mutate(pdays=sqrt(pdays)) %>% mutate(pdays=coalesce(pdays,0)) %>% count(pdays)

clean %>% ggplot(aes(x = pdays, fill = y)) + geom_histogram() + theme_minimal() + ggtitle("Distribution of Pdays")



### sqrt is best transformation for pdays to approach normality, except it would 
###remove about 30,000 observations ince, you guessed it, the sqrt of 0 is 0. 
##Anyway, there are 30,000  observations with 0, so  highly unlikely this will be able
### tell us anything about 'y'
```


```{r previous}
hist(1/(clean$previous))

clean %>% ggplot(aes(x=y, y=previous)) + geom_boxplot()

##remove outlier
clean <- clean %>% filter(previous<100)

clean %>% mutate(previous=1/previous)

clean %>% ggplot(aes(x = 1/previous, fill = y)) + geom_histogram() + theme_minimal() + ggtitle("Distribution of Previous")


###reciprocal transformation makes the most sense for previous variable, but even then, it's not really  normally distributed
###might be worth removing,  especially, since the reason it makes the most sense is bc the 0 is removed,
## due to the majority of observations being 0, thus 1/0= undefined (or in this case, infinity). Traash.
```


```{r Mutate}

## make relevant transformations
clean <- clean %>% mutate(balance=log(balance)) %>% filter(balance>=1) %>% mutate(duration=log(duration)) %>% filter(duration>=2)
clean <- clean %>% filter(!is.infinite(balance)) %>% filter(!is.na(balance)) %>% filter(!is.infinite(duration)) %>% filter(!is.na(duration))


```


```{r train and test sets}

num_clean <- select_if(clean, is.numeric)
y_col<- clean$y


num_clean <- cbind(num_clean, y_col)
num_clean <- num_clean %>% mutate(y=y_col) %>% select(!y_col)

set.seed(1)
test_index <- sample(1:nrow(clean), size = 0.2*nrow(clean))
test <- clean[test_index,]
train<- clean[-test_index,]
dim(test)
dim(train)
head(train)
head(clean)

##set y as factor
train$y <- as.factor(train$y)
test$y <- as.factor(test$y)


```

```{r balance train set}
library(ROSE)
##under sampling
under_train <- ovun.sample(y~., data=train, method="under")
under_train <- under_train$data
table(under_train$y)
under_train$y <- as.factor(under_train$y)
head(under_train)

#over sampling
over_train <- ovun.sample(y~., data=train, method="over")
over_train <- over_train$data
table(over_train$y)

#both
both_train <- ovun.sample(y~., data=train, method="both")
both_train <- both_train$data
table(both_train$y)
head(under_train)
```


```{r LDA}
library(MASS)
library(caret)

#under sample
under_lda <- lda(y~age+balance+day+duration, data=under_train)
summary(under_lda)
pred <- predict(under_lda, newdata=test[,-8])$class
pred2 <- predict(under_lda, newdata=test[,-8])
confusionMatrix(pred, test$y)

## Accuracy: 72.2%
## Sensitivity: 72%
## Specificity: 73.6%

#over sample
over_lda <- lda(y~age+balance+day+duration, data=over_train)
summary(over_lda)
pred_over <- predict(over_lda, newdata=test[,-8])$class

confusionMatrix(pred_over, test$y)


### Accuracy: 71.75%
### Sensitivity: 71.37%
### Specificity: 74.29%

# both sample
both_lda <- lda(y~age+balance+day+duration, data=both_train)
summary(both_lda)
pred_both <- predict(both_lda, newdata=test[,-8])$class

confusionMatrix(pred_both, test$y)

### Accuracy: 72.18%
### Sensitivity: 71.98%
### Specificity: 73.47%


### Under sample performed marginally better; however, given that only 4 numeric variables were used (only ones that met LDA assumptions), this method is not the best approach for this given dataset.
```

```{r  ROC Curve}
library(ROCR)

pred4 <- as.data.frame(pred2)
head(pred4)

round <- pred4$posterior.yes
pred5 <- prediction(round, test$y)
perf <- performance(pred5, measure = "tpr", x.measure = "fpr")
plot(perf, colorize=T, lwd=3)

### AUC
perf2 <- performance(pred5, measure = "auc", fpr.stop=0.5)
perf2@y.values[[1]][1]

```


```{r Random Forest}
library(randomForest)

## unbalanced data
summary(clean)

rf <- randomForest(y~education+balance+housing+loan+contact+duration+pdays+previous, data=train)
pred_rf <- predict(rf, newdata = test[-17])
confusionMatrix(pred_rf, test$y)

### Accuracy: 89.68%
### Sensitivity: 95.82%
### Specificity: 48.88%


### balanced data
### under sampling

under_rf <- randomForest(y~job + marital + education + balance + housing + 
    loan + contact + day + month + duration + campaign + poutcome, data=under_train)
pred_urf <- predict(under_rf, newdata = test[-17])
confusionMatrix(pred_urf, test$y)

### Accuracy: 82.89%
### Sensitivity: 81.85%
### Specificity: 89.80%

### over sample

over_rf <- randomForest(y~., data=over_train)
pred_orf <- predict(over_rf, newdata = test[-17])
confusionMatrix(pred_orf, test$y)


### Accuracy: 89.65%
### Sensitivity: 93.79%
### Specificity: 62.14%

### both sample

both_rf <- randomForest(y~., data=both_train)
pred_brf <- predict(both_rf, newdata = test[-17])
confusionMatrix(pred_brf, test$y)

### Accuracy: 87.77%
### Sensitivity: 89.43%
### Specificity: 76.73%

```


You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
