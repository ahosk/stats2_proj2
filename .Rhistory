plot(cv_model)
simple_model = glmnet(train_expl,train_resp,family = 'binomial')
plot_glmnet(simple_model,label=5,nresponse =3)
simple_model$lambda.min
#cv model
cv_model = cv.glmnet(train_expl,train_resp, family = 'binomial')
best_lambda = cv_model$lambda.min
plot(cv_model, label = 5, nresponse = 3)
best_lambda
simple_model = glm(train_expl,train_resp,family = 'binomial')
simple_model = glm(train_resp~train_expl,family = 'binomial')
plot_glmnet(simple_model,label=5,nresponse =3)
plot(simple_model,label=5,nresponse =3)
plot(simple_model)
## 75% of the sample size
smp_size <- floor(0.80 * nrow(df))
## set the seed to make your partition reproducible
set.seed(1235324)
train_ind <- sample(seq_len(nrow(df)), size = smp_size)
train_df <- df[train_ind, ]
test_df <- df[-train_ind, ]
#defining response variable
train_resp = train_df$y
test_resp = test_df$y
#recode yes/no to 1 and 0
train_resp = ifelse(train_resp =="yes",1,0)
test_resp = ifelse(test_resp =="yes",1,0)
#defining explanatory variables
train_expl = data.matrix(train_df[,1:16])
test_expl = data.matrix(test_df[,1:16])
train_resp = train_df$y
test_resp = test_df$y
#recode yes/no to 1 and 0
train_resp = ifelse(train_resp =="yes",1,0)
test_resp = ifelse(test_resp =="yes",1,0)
#defining explanatory variables
train_expl = data.matrix(train_df[,1:16])
test_expl = data.matrix(test_df[,1:16])
simple_model = glm(train_resp~train_expl,family = 'binomial')
plot(simple_model)
df[34477,]
df
df$balance = log(df$balance)
df$balance
df$balance = log1p(df$balance)
df$balance
df[61,]
e
df = read.csv(file.choose(),header = TRUE)
df[61,]
df = read.csv(file.choose(),header = TRUE)
df
df = df %>% filter(df$balance != 0)
df$y <- as.factor(df$y)
df$job = factor(df$job)
df$marital = factor(df$marital)
df$education = factor(df$education)
df$default = factor(df$default)
df$housing = factor(df$housing)
df$loan = factor(df$loan)
df$contact = factor(df$contact)
df$poutcome = factor(df$poutcome)
df$month = factor(df$month)
df$balance = log1p(df$balance)
df$balance
df = read.csv(file.choose(),header = TRUE)
df[46,]
df$balance = exp(df$balance)
df$balance
df
df$y <- as.factor(df$y)
df$job = factor(df$job)
df$marital = factor(df$marital)
df$education = factor(df$education)
df$default = factor(df$default)
df$housing = factor(df$housing)
df$loan = factor(df$loan)
df$contact = factor(df$contact)
df$poutcome = factor(df$poutcome)
df$month = factor(df$month)
## 75% of the sample size
smp_size <- floor(0.80 * nrow(df))
## set the seed to make your partition reproducible
set.seed(1235324)
train_ind <- sample(seq_len(nrow(df)), size = smp_size)
train_df <- df[train_ind, ]
test_df <- df[-train_ind, ]
#defining response variable
train_resp = train_df$y
test_resp = test_df$y
#recode yes/no to 1 and 0
train_resp = ifelse(train_resp =="yes",1,0)
test_resp = ifelse(test_resp =="yes",1,0)
#defining explanatory variables
train_expl = data.matrix(train_df[,1:16])
test_expl = data.matrix(test_df[,1:16])
#defining response variable
train_resp = train_df$y
test_resp = test_df$y
#recode yes/no to 1 and 0
train_resp = ifelse(train_resp =="yes",1,0)
test_resp = ifelse(test_resp =="yes",1,0)
#defining explanatory variables
train_expl = data.matrix(train_df[,1:16])
test_expl = data.matrix(test_df[,1:16])
simple_model = glm(train_resp~train_expl,family = 'binomial')
df = read.csv(file.choose(),header = TRUE)
df
#df = df %>% filter(df$balance != 0)
df$y <- as.factor(df$y)
df$job = factor(df$job)
df$marital = factor(df$marital)
df$education = factor(df$education)
df$default = factor(df$default)
df$housing = factor(df$housing)
df$loan = factor(df$loan)
df$contact = factor(df$contact)
df$poutcome = factor(df$poutcome)
df$month = factor(df$month)
#df$y = ifelse(df$y =="yes",1,0)
df$y <- as.factor(df$y)
df$job = factor(df$job)
df$marital = factor(df$marital)
df$education = factor(df$education)
df$default = factor(df$default)
df$housing = factor(df$housing)
df$loan = factor(df$loan)
df$contact = factor(df$contact)
df$poutcome = factor(df$poutcome)
df$month = factor(df$month)
## 75% of the sample size
smp_size <- floor(0.80 * nrow(df))
## set the seed to make your partition reproducible
set.seed(1235324)
train_ind <- sample(seq_len(nrow(df)), size = smp_size)
train_df <- df[train_ind, ]
test_df <- df[-train_ind, ]
#defining response variable
train_resp = train_df$y
test_resp = test_df$y
#recode yes/no to 1 and 0
#train_resp = ifelse(train_resp =="yes",1,0)
#test_resp = ifelse(test_resp =="yes",1,0)
#defining explanatory variables
train_expl = data.matrix(train_df[,1:16])
test_expl = data.matrix(test_df[,1:16])
df[46,]
simple_model = glm(train_resp~train_expl,family = 'binomial')
plot(simple_model)
cv_model = cv.glmnet(train_expl,train_resp, family = 'binomial')
best_lambda = cv_model$lambda.min
plot(cv_model, label = 5, nresponse = 3)
best_lambda
#plot cv model
plot(cv_model)
best_model = glmnet(train_expl,train_resp, labmda = best_lambda,family = 'binomial')
best_model
coef(best_model,best_lambda)
#assess lasso model
assess.glmnet(best_model,test_expl,test_resp, family = 'binomial',s = best_lambda)
#return confusion matrix from lasso model
confusion.glmnet(best_model,test_expl,test_resp,family = 'binomial',s=best_lambda)
#plot roc curve from lasso model
plot(roc.glmnet(best_model,test_expl,test_resp,family = 'binomial',s=best_lambda))
plot_glmnet(best_model, label=5,nresponse = 3)
lda_training = lda(y ~.,train_df)
library(MASS)
lda_training = lda(y ~.,train_df)
lda_training
p = predict(lda_training,train_df)
ldahist(data = p$x[,1],g = train_df$y)
lda_training
res.pca = prcomp(df,scale = TRUE)
ldahist(data = p$x[,1],g = train_df$y)
ldahist(data = p$x[,2],g = train_df$y)
ldahist(data = p$x,g = train_df$y)
coef(best_model,best_lambda)
#lasso model
best_model = glmnet(train_expl,train_resp, s = best_lambda,family = 'binomial')
#lasso model
best_model = glmnet(train_expl,train_resp, s= "lambda.min",family = 'binomial')
simple_model = glm(train_resp~train_expl,family = 'binomial')
plot(simple_model)
simple_model$lambda.min
#cv model
cv_model = cv.glmnet(train_expl,train_resp, family = 'binomial')
best_lambda = cv_model$lambda.min
best_lambda
#plot cv model
plot(cv_model)
#lasso model
best_model = glmnet(train_expl,train_resp, lambda = best_lambda,family = 'binomial')
coef(best_model,best_lambda)
simple_model$weights
plot(simple_model$residuals)
plot(simple_model$aic)
simple_model$aic
prop.table(table(df$y))
classifier.lm = glm(formula = y ~ .,
family = binomial,
data = train_df)
pred_lm = predict(classifier.lm, type='response', newdata=test_expl)
test_expl
pred_lm = predict(classifier.lm, type='response', newdata=test_df[-17])
# plot the prediction distribution
predictions_LR <- data.frame(y = test_df$y, pred = NA)
predictions_LR$pred <- pred_lm
plot_pred_type_distribution(predictions_LR,0.30)
library(knitr)      # web widget
library(tidyverse)  # data manipulation
library(data.table) # fast file reading
library(ROCR)       # rocr analysis
install.packages('ROCR')
library(ROCR)       # rocr analysis
predictions_LR <- data.frame(y = test_df$y, pred = NA)
predictions_LR$pred <- pred_lm
plot_pred_type_distribution(predictions_LR,0.30)
plot_pred_type_distribution <- function(df, threshold) {
v <- rep(NA, nrow(df))
v <- ifelse(df$pred >= threshold & df$y == 1, "TP", v)
v <- ifelse(df$pred >= threshold & df$y == 0, "FP", v)
v <- ifelse(df$pred < threshold & df$y == 1, "FN", v)
v <- ifelse(df$pred < threshold & df$y == 0, "TN", v)
df$pred_type <- v
ggplot(data=df, aes(x=y, y=pred)) +
geom_violin(fill='black', color=NA) +
geom_jitter(aes(color=pred_type), alpha=0.6) +
geom_hline(yintercept=threshold, color="red", alpha=0.6) +
scale_color_discrete(name = "type") +
labs(title=sprintf("Threshold at %.2f", threshold))
}
plot_pred_type_distribution(predictions_LR,0.30)
ggplot(data=df, aes(x=y, y=pred)) +
geom_violin(fill='black', color='black') +
geom_jitter(aes(color=pred_type), alpha=0.6) +
geom_hline(yintercept=threshold, color="red", alpha=0.6) +
scale_color_discrete(name = "type") +
labs(title=sprintf("Threshold at %.2f", threshold))
plot_pred_type_distribution <- function(df, threshold) {
v <- rep(NA, nrow(df))
v <- ifelse(df$pred >= threshold & df$y == 1, "TP", v)
v <- ifelse(df$pred >= threshold & df$y == 0, "FP", v)
v <- ifelse(df$pred < threshold & df$y == 1, "FN", v)
v <- ifelse(df$pred < threshold & df$y == 0, "TN", v)
df$pred_type <- v
ggplot(data=df, aes(x=y, y=pred)) +
geom_violin(fill='black', color='black') +
geom_jitter(aes(color=pred_type), alpha=0.6) +
geom_hline(yintercept=threshold, color="red", alpha=0.6) +
scale_color_discrete(name = "type") +
labs(title=sprintf("Threshold at %.2f", threshold))
}
plot_pred_type_distribution(predictions_LR,0.30)
# choose the best threshold as 0.30
test.eval.LR = binclass_eval(test_df[, 17], pred_lm > 0.30)
binclass_eval = function (actual, predict) {
cm = table(as.integer(actual), as.integer(predict), dnn=c('Actual','Predicted'))
ac = (cm['1','1']+cm['0','0'])/(cm['0','1'] + cm['1','0'] + cm['1','1'] + cm['0','0'])
pr = cm['1','1']/(cm['0','1'] + cm['1','1'])
rc = cm['1','1']/(cm['1','0'] + cm['1','1'])
fs = 2* pr*rc/(pr+rc)
list(cm=cm, recall=rc, precision=pr, fscore=fs, accuracy=ac)
}
ggplot(data=df, aes(x=y, y=pred)) +
geom_violin(fill='black', color=NA) +
geom_jitter(aes(color=pred_type), alpha=0.6) +
geom_hline(yintercept=threshold, color="red", alpha=0.6) +
scale_color_discrete(name = "type") +
labs(title=sprintf("Threshold at %.2f", threshold))
plot_pred_type_distribution <- function(df, threshold) {
v <- rep(NA, nrow(df))
v <- ifelse(df$pred >= threshold & df$y == 1, "TP", v)
v <- ifelse(df$pred >= threshold & df$y == 0, "FP", v)
v <- ifelse(df$pred < threshold & df$y == 1, "FN", v)
v <- ifelse(df$pred < threshold & df$y == 0, "TN", v)
df$pred_type <- v
ggplot(data=df, aes(x=y, y=pred)) +
geom_violin(fill='black', color=NA) +
geom_jitter(aes(color=pred_type), alpha=0.6) +
geom_hline(yintercept=threshold, color="red", alpha=0.6) +
scale_color_discrete(name = "type") +
labs(title=sprintf("Threshold at %.2f", threshold))
}
# choose the best threshold as 0.30
test.eval.LR = binclass_eval(test_df[, 17], pred_lm > 0.30)
# Making the Confusion Matrix
test.eval.LR$cm
predict_lm
pred_lm = predict(classifier.lm, type='response', newdata=test_df[-17])
pred_lm
rocr.pred = prediction(predictions = pred.DT[,2], labels = test_set$y)
#assess lasso model
assess.glmnet(best_model,test_expl,test_resp, family = 'binomial',s = best_lambda)
#return confusion matrix from lasso model
confusion.glmnet(best_model,test_expl,test_resp,family = 'binomial',s=best_lambda)
#plot roc curve from lasso model
plot(roc.glmnet(best_model,test_expl,test_resp,family = 'binomial',s=best_lambda))
plot_glmnet(best_model, label=5,nresponse = 3)
plot_glmnet(best_model, label=5,nresponse = 3)
#assess lasso model
assess.glmnet(cv_model,test_expl,test_resp, family = 'binomial',s = best_lambda)
#return confusion matrix from lasso model
confusion.glmnet(cv_model,test_expl,test_resp,family = 'binomial',s=best_lambda)
#plot roc curve from lasso model
plot(roc.glmnet(cv_model,test_expl,test_resp,family = 'binomial',s=best_lambda))
simple_model = glmnet(train_resp~train_expl,family = 'binomial')
#plot cv model
plot(cv_model)
#lasso model
best_model = glmnet(train_expl,train_resp, lambda = best_lambda,family = 'binomial')
#lasso model
best_model = glmnet(train_expl,train_resp, lambda = best_lambda,family = 'binomial')
coef(best_model,best_lambda)
#assess lasso model
assess.glmnet(best_model,test_expl,test_resp, family = 'binomial',lambda = best_lambda)
#return confusion matrix from lasso model
confusion.glmnet(best_model,test_expl,test_resp,family = 'binomial',lambda=best_lambda)
#assess lasso model
assess.glmnet(best_model,test_expl,test_resp, family = 'binomial',s = best_lambda)
#plot roc curve from lasso model
plot(roc.glmnet(best_model,test_expl,test_resp,family = 'binomial',s=best_lambda))
#cv model
cv_model = cv.glmnet(train_expl,train_resp, alpha = 0, family = 'binomial')
best_lambda = cv_model$lambda.min
best_lambda
#plot cv model
plot(cv_model)
best_model = glmnet(train_expl,train_resp, alpha = 0, lambda = best_lambda,family = 'binomial')
coef(best_model,best_lambda)
ridge_cv_model = cv.glmnet(train_expl,train_resp, alpha = 0, family = 'binomial')
ridge_best_lambda = ridge_cv_model$lambda.min
ridge_best_lambda
#plot cv model
plot(ridge_cv_model)
#lasso model
ridge_best_model = glmnet(train_expl,train_resp, alpha = 0, lambda = ridge_best_lambda,family = 'binomial')
coef(ridge_best_model,ridge_best_lambda)
#assess lasso model
assess.glmnet(ridge_best_model,test_expl,test_resp, family = 'binomial',s = ridge_best_lambda)
#return confusion matrix from lasso model
confusion.glmnet(ridge_best_model,test_expl,test_resp,family = 'binomial',s=ridge_best_lambda)
#plot roc curve from lasso model
plot(roc.glmnet(ridge_best_model,test_expl,test_resp,family = 'binomial',s=ridge_best_lambda))
#cv model
mid_cv_model = cv.glmnet(train_expl,train_resp,alpha = 0.5,family = 'binomial')
mid_best_lambda = mid_cv_model$lambda.min
mid_best_lambda
#plot cv model
plot(mid_cv_model)
#lasso model
mid_best_model = glmnet(train_expl,train_resp,alpha = 0.5, lambda = mid_best_lambda,family = 'binomial')
coef(mid_best_model,mid_best_lambda)
#assess lasso model
assess.glmnet(mid_best_model,test_expl,test_resp, family = 'binomial',s = mid_best_lambda)
#return confusion matrix from lasso model
confusion.glmnet(mid_best_model,test_expl,test_resp,family = 'binomial',s=mid_best_lambda)
#plot roc curve from lasso model
plot(roc.glmnet(mid_best_model,test_expl,test_resp,family = 'binomial',s=mid_best_lambda))
## 75% of the sample size
smp_size <- floor(0.70 * nrow(df))
## set the seed to make your partition reproducible
set.seed(1235324)
train_ind <- sample(seq_len(nrow(df)), size = smp_size)
train_df <- df[train_ind, ]
test_df <- df[-train_ind, ]
#defining response variable
train_resp = train_df$y
test_resp = test_df$y
#recode yes/no to 1 and 0
#train_resp = ifelse(train_resp =="yes",1,0)
#test_resp = ifelse(test_resp =="yes",1,0)
#defining explanatory variables
train_expl = data.matrix(train_df[,1:16])
test_expl = data.matrix(test_df[,1:16])
#cv model
lasso_cv_model = cv.glmnet(train_expl,train_resp,alpha = 1,family = 'binomial')
lasso_best_lambda = lasso_cv_model$lambda.min
best_lambda
#plot cv model
plot(lasso_cv_model)
#lasso model
lasso_best_model = glmnet(train_expl,train_resp,alpha = 1, lambda = lasso_best_lambda,family = 'binomial')
coef(lasso_best_model,lasso_best_lambda)
#assess lasso model
assess.glmnet(lasso_best_model,test_expl,test_resp, family = 'binomial',s = lasso_best_lambda)
#return confusion matrix from lasso model
confusion.glmnet(lasso_best_model,test_expl,test_resp,family = 'binomial',s=lasso_best_lambda)
#plot roc curve from lasso model
plot(roc.glmnet(lasso_best_model,test_expl,test_resp,family = 'binomial',s=lasso_best_lambda))
#cv model
lasso_cv_model = cv.glmnet(train_expl,train_resp,alpha = 1,family = 'binomial')
lasso_best_lambda = lasso_cv_model$lambda.min
best_lambda
#plot cv model
plot(lasso_cv_model)
#lasso model
lasso_best_model = glmnet(train_expl,train_resp,alpha = 1, lambda = lasso_best_lambda,family = 'binomial')
coef(lasso_best_model,lasso_best_lambda)
#assess lasso model
assess.glmnet(lasso_best_model,test_expl,test_resp, family = 'binomial',s = lasso_best_lambda)
#return confusion matrix from lasso model
confusion.glmnet(lasso_best_model,test_expl,test_resp,family = 'binomial',s=lasso_best_lambda)
#plot roc curve from lasso model
plot(roc.glmnet(lasso_best_model,test_expl,test_resp,family = 'binomial',s=lasso_best_lambda))
## 75% of the sample size
smp_size <- floor(0.80 * nrow(df))
## set the seed to make your partition reproducible
set.seed(57)
train_ind <- sample(seq_len(nrow(df)), size = smp_size)
train_df <- df[train_ind, ]
test_df <- df[-train_ind, ]
#defining response variable
train_resp = train_df$y
test_resp = test_df$y
#recode yes/no to 1 and 0
#train_resp = ifelse(train_resp =="yes",1,0)
#test_resp = ifelse(test_resp =="yes",1,0)
#defining explanatory variables
train_expl = data.matrix(train_df[,1:16])
test_expl = data.matrix(test_df[,1:16])
#cv model
lasso_cv_model = cv.glmnet(train_expl,train_resp,alpha = 1,family = 'binomial')
lasso_best_lambda = lasso_cv_model$lambda.min
best_lambda
#plot cv model
plot(lasso_cv_model)
#lasso model
lasso_best_model = glmnet(train_expl,train_resp,alpha = 1, lambda = lasso_best_lambda,family = 'binomial')
coef(lasso_best_model,lasso_best_lambda)
#assess lasso model
assess.glmnet(lasso_best_model,test_expl,test_resp, family = 'binomial',s = lasso_best_lambda)
#return confusion matrix from lasso model
confusion.glmnet(lasso_best_model,test_expl,test_resp,family = 'binomial',s=lasso_best_lambda)
#plot roc curve from lasso model
plot(roc.glmnet(lasso_best_model,test_expl,test_resp,family = 'binomial',s=lasso_best_lambda))
#cv model
ridge_cv_model = cv.glmnet(train_expl,train_resp, alpha = 0, family = 'binomial')
ridge_best_lambda = ridge_cv_model$lambda.min
ridge_best_lambda
#plot cv model
plot(ridge_cv_model)
#lasso model
ridge_best_model = glmnet(train_expl,train_resp, alpha = 0, lambda = ridge_best_lambda,family = 'binomial')
coef(ridge_best_model,ridge_best_lambda)
#assess lasso model
assess.glmnet(ridge_best_model,test_expl,test_resp, family = 'binomial',s = ridge_best_lambda)
#return confusion matrix from lasso model
confusion.glmnet(ridge_best_model,test_expl,test_resp,family = 'binomial',s=ridge_best_lambda)
#plot roc curve from lasso model
plot(roc.glmnet(ridge_best_model,test_expl,test_resp,family = 'binomial',s=ridge_best_lambda))
relaxed_cv_model = cv.glmnet(train_expl,train_resp,alpha = 0.5,family = 'binomial',relax = TRUE)
mid_best_lambda = mid_cv_model$lambda.min
mid_best_lambda
#plot cv model
plot(relaxed_cv_model)
relax_best_model = glmnet(train_expl,train_resp,alpha = 0.5, lambda = relax_best_lambda,family = 'binomial',relax = TRUE)
relaxed_best_lambda = relaxed_cv_model$lambda.min
relaxed_best_model = glmnet(train_expl,train_resp,alpha = 0.5, lambda = relax_best_lambda,family = 'binomial',relax = TRUE)
relaxed_best_model = glmnet(train_expl,train_resp,alpha = 0.5, lambda = relaxed_best_lambda,family = 'binomial',relax = TRUE)
coef(relaxed_best_model,relaxed_best_lambda)
#assess lasso model
assess.glmnet(relaxed_best_model,test_expl,test_resp, family = 'binomial',s = mid_best_lambda)
#return confusion matrix from lasso model
confusion.glmnet(relaxed_best_model,test_expl,test_resp,family = 'binomial',s=mid_best_lambda)
#plot roc curve from lasso model
plot(roc.glmnet(relaxed_best_model,test_expl,test_resp,family = 'binomial',s=mid_best_lambda))
#plot roc curve from lasso model
plot(roc.glmnet(relaxed_best_model,test_expl,test_resp,family = 'binomial',s=mid_best_lambda,relax = TRUE))
#return confusion matrix from lasso model
confusion.glmnet(relaxed_best_model,test_expl,test_resp,family = 'binomial',s=mid_best_lambda,relax = TRUE)
#assess lasso model
assess.glmnet(relaxed_best_model,test_expl,test_resp, family = 'binomial',s = mid_best_lambda,relax = TRUE)
#plot cv model
plot(relaxed_cv_model)
#cv model
relaxed_cv_model = cv.glmnet(train_expl,train_resp,alpha = 1,family = 'binomial',relax = TRUE)
relaxed_best_lambda = relaxed_cv_model$lambda.min
#plot cv model
plot(relaxed_cv_model)
#lasso model
relaxed_best_model = glmnet(train_expl,train_resp,alpha = 1, lambda = relaxed_best_lambda,family = 'binomial',relax = TRUE)
coef(relaxed_best_model,relaxed_best_lambda)
#assess lasso model
assess.glmnet(relaxed_best_model,test_expl,test_resp, family = 'binomial',s = mid_best_lambda,relax = TRUE)
#return confusion matrix from lasso model
confusion.glmnet(relaxed_best_model,test_expl,test_resp,family = 'binomial',s=mid_best_lambda,relax = TRUE)
#plot roc curve from lasso model
plot(roc.glmnet(relaxed_best_model,test_expl,test_resp,family = 'binomial',s=mid_best_lambda,relax = TRUE))
varImp(relaxed_cv_model, lambda = relaxed_cv_model$lambda.min)
varImp(relaxed_cv_model, lambda = relaxed_best_model$lambda.min)
coefs = coef(relaxed_best_model)[,1]
coefs = sort(abs(coefs), decreasing = F)
coefs
table(coefs)
coefs
varImp(relaxed_best_model)
varImp(relaxed_best_model,lambda = relaxed_best_lambda)
varImp(relaxed_best_model,lambda = relaxed_best_lambda, scale = False)
varImp(relaxed_best_model,lambda = relaxed_best_lambda, scale = FALSE)
ggplot2::ggplot(varImp(relaxed_best_model,lambda = relaxed_best_lambda, scale = FALSE))
varImp(relaxed_best_model,lambda = relaxed_best_lambda, scale = FALSE)
plot(relax_var_imp)
relax_var_imp = varImp(relaxed_best_model,lambda = relaxed_best_lambda, scale = FALSE)
plot(relax_var_imp)
plot(relax_var_imp,sacale = FALSE)
relax_var_imp
#lasso model
relaxed_best_model = relax.glmnet(train_expl,train_resp,alpha = 1, lambda = relaxed_best_lambda,family = 'binomial')
#lasso model
relaxed_best_model = glmnet(train_expl,train_resp,alpha = 1, lambda = relaxed_best_lambda,family = 'binomial',relax = TRUE)
coef(relaxed_best_model,relaxed_best_lambda)
relax_var_imp
